{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f1467e",
   "metadata": {},
   "source": [
    "# Basic DTW Code\n",
    "Code from https://towardsdatascience.com/dynamic-time-warping-3933f25fcdd  \n",
    "This code implements a simple DTW measure between two series represented as lists.  \n",
    "It allows for series of different lengths and has a `window` parameter that determines the amount of warping allowed.  \n",
    "For series of different lengths, the minimum warping will be the difference in the lengths.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43d7401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73329be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw(s, t, window):\n",
    "    n, m = len(s), len(t)\n",
    "    w = np.max([window, abs(n-m)]) # warping cannot be less than the difference in lengths. \n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    \n",
    "    #initialize cells (1...n, 0) and cells (0, 1...m) as infinite, cell (0,0) as 0\n",
    "    for i in range(n+1):\n",
    "        for j in range(m+1):\n",
    "            dtw_matrix[i, j] = np.inf\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    \n",
    "    #calculate the value of the rest cells in the n*m size table\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            dtw_matrix[i, j] = 0\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            cost = abs(s[i-1] - t[j-1])\n",
    "            # take last min from a square box\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "    # print(dtw_matrix)\n",
    "    return dtw_matrix[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "361b8066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,3,5]\n",
    "b = [1,2,2,2,2,2,2,4]\n",
    "dtw(a,b, window = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "908866ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [7,7,8,9,10,10,7,4,2,1,2,4,7,11,10,9,7]\n",
    "x2 = [7,8,10,10,8,7,3,2,2,4,6,12,12,9,7,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11b74182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtw_0 = dtw(x1,x2,window = 1)\n",
    "dtw_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ec5b9",
   "metadata": {},
   "source": [
    "Works also for numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c76a91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[7,7,8,9,10,10,7,4,2,1,2,4,7,11,10,9,7],\n",
    "                [7,8,10,10,8,7,3,2,2,4,6,12,12,9,7,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5094a0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  7,  8,  9, 10, 10,  7,  4,  2,  1,  2,  4,  7, 11, 10,  9,  7])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2db454b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 43.0\n",
      "1 19.0\n",
      "2 9.0\n",
      "3 9.0\n",
      "4 9.0\n",
      "5 9.0\n",
      "6 9.0\n",
      "7 9.0\n",
      "8 9.0\n",
      "9 9.0\n"
     ]
    }
   ],
   "source": [
    "for w in range(10):\n",
    "    dtw_n = dtw(x[0],x[1],window = w)\n",
    "    print(w, dtw_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e9756",
   "metadata": {},
   "source": [
    "# Task 1: 1-NN DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa22440b",
   "metadata": {},
   "source": [
    "## 1. Use the DTW function in the notebook to implement a simple 1-NN classifier for time-series data.\n",
    "Here I defined three methods to implement 1-NN classfier: calc_distance_dtw(), get_neighbor(), and get prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61729b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance_dtw(s, t, window):\n",
    "    \"\"\"Function use DTW algo to calculate distance between two series\"\"\"\n",
    "    n, m = len(s), len(t)\n",
    "    w = np.max([window, abs(n-m)]) # warping cannot be less than the difference in lengths. \n",
    "    dtw_matrix = np.zeros((n+1, m+1))\n",
    "    \n",
    "    #initialize cells (1...n, 0) and cells (0, 1...m) as infinite, cell (0,0) as 0\n",
    "    for i in range(n+1):\n",
    "        for j in range(m+1):\n",
    "            dtw_matrix[i, j] = np.inf\n",
    "    dtw_matrix[0, 0] = 0\n",
    "    \n",
    "    #calculate the value of the rest cells in the n*m size table\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            dtw_matrix[i, j] = 0\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(np.max([1, i-w]), np.min([m, i+w])+1):\n",
    "            cost = abs(s[i-1] - t[j-1])\n",
    "            # take last min from a square box\n",
    "            last_min = np.min([dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1]])\n",
    "            dtw_matrix[i, j] = cost + last_min\n",
    "    return dtw_matrix[-1, -1]\n",
    "\n",
    "def get_neighbor(test_row, train_dataset, window):\n",
    "    \"\"\"Function takes test_row and dataset (a dataframe) as parameters, returns nearest row in the dataset to the test_row\"\"\"\n",
    "    #a list to store all distances between rows and single test row\n",
    "    distances = []\n",
    "    #iterate through dataset, skip test_row\n",
    "    for index in train_dataset.index:\n",
    "        distances.append(calc_distance_dtw(s = list(test_row), t=list(train_dataset.iloc[index]), window=window))\n",
    "    #convert the list to a dataframe, use the index from dataset\n",
    "    df_distances = pd.DataFrame(data=distances, index=train_dataset.index, columns=['distance'])\n",
    "    #sort the distances by values, take the smallest(nearest) one, say, the first row\n",
    "    df_neighbor = df_distances.sort_values(axis=0, by='distance')\n",
    "    #return this row\n",
    "    return df_neighbor.iloc[0]\n",
    "\n",
    "def get_prediction(df_neighbor, y_classes):\n",
    "    \"\"\"Function takes the result from get_neighbor() function and y/target dataframe, returns the prediction of test_row\"\"\"\n",
    "    #get the laebl/class of the nearest neighbor, make prediction\n",
    "    prediction = float(y_classes.iloc[df_neighbor.name])\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc6863",
   "metadata": {},
   "source": [
    "## 2. Test the performance of this classifier on the dataset provided in the file UMD_TEST.txt. This is a three-class synthetic time-series dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be84a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#read the text file to a dataframe\n",
    "df = pd.read_table(\"UMD_TEST.txt\", delimiter=\"  \", header=None)\n",
    "#derive target column from original dataset, assign it to y_classes\n",
    "target_dataset = pd.DataFrame(df.iloc[:, 0])\n",
    "#drop target column in original dataset, assign the rest to train_dataset\n",
    "feature_dataset = df.drop(0, axis=1)\n",
    "#spilt the data to 75%(train) and 25%(test), and reset index for them\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_dataset, target_dataset, test_size=0.25, random_state=0)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "54c8d077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'window_size': 0,\n",
       " 'accuracy_score': 0.8611111111111112,\n",
       " 'confusion_matrix': array([[13,  2,  0],\n",
       "        [ 0,  8,  0],\n",
       "        [ 0,  3, 10]])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def performance_oneNN_DTW(window):\n",
    "    #list to store all predicted values for X_test\n",
    "    y_test_pred = []\n",
    "    result_dict = {}\n",
    "    #iterate through rows in X_test set, make predictions for each test_row based on X_train set\n",
    "    for i in range(X_test.shape[0]):\n",
    "        df_neighbor = get_neighbor(test_row=X_test.iloc[i], train_dataset=X_train, window=window)\n",
    "        prediction_result = get_prediction(df_neighbor=df_neighbor, y_classes=y_train)\n",
    "        y_test_pred.append(prediction_result)\n",
    "\n",
    "    #generate the accuracy score for this classfier\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    #generate confusion matrix for this classfier\n",
    "    confusion =  confusion_matrix(y_test, y_test_pred)\n",
    "    #store all results to a dict\n",
    "    result_dict['window_size'] = window\n",
    "    result_dict['accuracy_score'] = accuracy\n",
    "    result_dict['confusion_matrix'] = confusion\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "#call the function with window size == 0\n",
    "performance_oneNN_DTW(window=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4591020",
   "metadata": {},
   "source": [
    "## 3. Given that the time-series are all the same length (150 ticks) Euclidean distance can also be used as distance metric. Compare the 1-NN DTW performance with 1-NN Euclidean. Use the scikit-learn implementation for the Euclidean model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1e155803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results are: [1. 2. 3. 2. 3. 3. 2. 1. 2. 1. 3. 3. 2. 1. 2. 1. 1. 1. 3. 2. 2. 3. 2. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn oneNN Classfier is: 0.8611111111111112\n",
      "Confusion matrix of sklearn oneNN Classifer is:\n",
      " [[12  3  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#new a class instance, p = 2 means this will be equivalent to Euclidean distance\n",
    "sklearn_classfier = KNeighborsClassifier(n_neighbors=1, p=2)\n",
    "#fit the classfier from the train dataset\n",
    "sklearn_classfier.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "#predict test dataset\n",
    "y_test_pred = sklearn_classfier.predict(X_test.to_numpy())\n",
    "print(\"Prediction results are:\", y_test_pred)\n",
    "#accuracy score\n",
    "print(\"Accuracy score for sklearn oneNN Classfier is:\", accuracy_score(y_test, y_test_pred))\n",
    "#confusion matrix\n",
    "print(\"Confusion matrix of sklearn oneNN Classifer is:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49349628",
   "metadata": {},
   "source": [
    "<h5><b>Conclusion</b></h5>\n",
    "<p><b>\n",
    "In Task1-2, we've got the following results:<br>\n",
    "&nbsp;&nbsp;{'window_size': 0,<br>\n",
    "&nbsp;&nbsp;'accuracy_score': 0.8611111111111112,<br>\n",
    "&nbsp;&nbsp;'confusion_matrix': <br>\n",
    "    &nbsp;&nbsp;&nbsp;([[13,  2,  0],<br>\n",
    "    &nbsp;&nbsp;&nbsp;[ 0,  8,  0],<br>\n",
    "    &nbsp;&nbsp;&nbsp;[ 0,  3, 10]])}<br>\n",
    "</p></b>\n",
    "\n",
    "<p><b>\n",
    "Here, we got:<br>\n",
    "&nbsp;&nbsp; 'accuracy_score': 0.8611111111111112<br>\n",
    "&nbsp;&nbsp; 'Confusion Matrix': <br>\n",
    "&nbsp;&nbsp;&nbsp;[[12  3  0]<br>\n",
    "&nbsp;&nbsp;&nbsp;[ 0  8  0]<br>\n",
    "&nbsp;&nbsp;&nbsp;[ 0  2 11]]<br>\n",
    "</p></b>\n",
    "\n",
    "<p><b>\n",
    "Comparing the two, we can see that they both have the same accuracy score, there is a small difference in their confusion matrix, but these two matrices are similar matrices because they have the same rank.<br>\n",
    "We can therefore conclude that the two are in agreement in terms of accuracy, but there are very small differences in the prediction of certain categories.\n",
    "</p></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29721d5e",
   "metadata": {},
   "source": [
    "## 4. Find the best value for the window parameter for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "337251e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'window_size': 0, 'accuracy_score': 0.8611111111111112, 'confusion_matrix': array([[13,  2,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  3, 10]])}\n",
      "{'window_size': 1, 'accuracy_score': 0.8611111111111112, 'confusion_matrix': array([[13,  2,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  3, 10]])}\n",
      "{'window_size': 2, 'accuracy_score': 0.8888888888888888, 'confusion_matrix': array([[13,  2,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  2, 11]])}\n",
      "{'window_size': 3, 'accuracy_score': 0.9166666666666666, 'confusion_matrix': array([[13,  2,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  1, 12]])}\n",
      "{'window_size': 4, 'accuracy_score': 0.9166666666666666, 'confusion_matrix': array([[13,  2,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  1, 12]])}\n",
      "{'window_size': 5, 'accuracy_score': 0.9444444444444444, 'confusion_matrix': array([[14,  1,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  1, 12]])}\n",
      "{'window_size': 6, 'accuracy_score': 0.9444444444444444, 'confusion_matrix': array([[14,  1,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  1, 12]])}\n",
      "{'window_size': 7, 'accuracy_score': 0.9444444444444444, 'confusion_matrix': array([[14,  1,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  1, 12]])}\n",
      "{'window_size': 8, 'accuracy_score': 0.9444444444444444, 'confusion_matrix': array([[14,  1,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  1, 12]])}\n",
      "{'window_size': 9, 'accuracy_score': 0.9444444444444444, 'confusion_matrix': array([[14,  1,  0],\n",
      "       [ 0,  8,  0],\n",
      "       [ 0,  1, 12]])}\n"
     ]
    }
   ],
   "source": [
    "#here we use a for loop to test which window size will get the best accuracy score\n",
    "for i in range(10):\n",
    "    print(performance_oneNN_DTW(window=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d2659",
   "metadata": {},
   "source": [
    "<h5><b>Conclusion</b></h5>\n",
    "<p><b>From the output we can conclude that when window size is greater than or equals to 5, the accuracy score will be the highest, which is 0.944</p></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a558d1b",
   "metadata": {},
   "source": [
    "# Task 2: k-NN DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0418878e",
   "metadata": {},
   "source": [
    "## 1. The k-NN classifier in scikit-learn has a metric parameter that allows for user-defined distance metrics. Adapt the DTW code provided so that it can be incorporated in a scikit-learn k-NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "47b0527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the parameter 'metric' to my own function 'calc_distance_dtw()', so the sklearn classfier will use this function to calculate distance; we still set number of neighbors to 1, window size to 0.\n",
    "sklearn_classfier = KNeighborsClassifier(metric=calc_distance_dtw, n_neighbors=1, metric_params={'window': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d2b36",
   "metadata": {},
   "source": [
    "## 2. Test the performance of this classifier and compare with the 1-NN results from Task 1. Verify that the 1-NN results are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e8701c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results are: [1. 2. 3. 2. 3. 2. 2. 1. 2. 1. 3. 3. 2. 1. 2. 1. 1. 1. 3. 2. 2. 3. 1. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn kNN Classfier (DTW distance) is:\n",
      " 0.8611111111111112\n",
      "Confusion matrix of sklearn kNN Classifer (DTW distance) is:\n",
      " [[13  2  0]\n",
      " [ 0  8  0]\n",
      " [ 0  3 10]]\n"
     ]
    }
   ],
   "source": [
    "#test it\n",
    "#fit the classfier with train set\n",
    "sklearn_classfier.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "#make predictions\n",
    "y_test_pred = sklearn_classfier.predict(X_test.to_numpy())\n",
    "print(\"Prediction results are:\", y_test_pred)\n",
    "#check accuracy\n",
    "print(\"Accuracy score for sklearn kNN Classfier (DTW distance) is:\\n\", accuracy_score(y_test, y_test_pred))\n",
    "#check confusion metrics\n",
    "print(\"Confusion matrix of sklearn kNN Classifer (DTW distance) is:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03898144",
   "metadata": {},
   "source": [
    "<h5><b>Conclusion</b></h5>\n",
    "<p><b>\n",
    "In Task1-2, we've got the following results:<br>\n",
    "&nbsp;&nbsp;{'window_size': 0,<br>\n",
    "&nbsp;&nbsp;'accuracy_score': 0.8611111111111112,<br>\n",
    "&nbsp;&nbsp;'confusion_matrix': <br>\n",
    "    &nbsp;&nbsp;&nbsp;([[13,  2,  0],<br>\n",
    "    &nbsp;&nbsp;&nbsp;[ 0,  8,  0],<br>\n",
    "    &nbsp;&nbsp;&nbsp;[ 0,  3, 10]])}<br>\n",
    "</p></b>\n",
    "\n",
    "<p><b>\n",
    "Here we got:\n",
    "&nbsp;&nbsp;'accuracy_score':<br>\n",
    "0.8611111111111112\n",
    "&nbsp;&nbsp;'confusion_matrix':\n",
    " [[13  2  0]\n",
    " [ 0  8  0]\n",
    " [ 0  3 10]]\n",
    "</p></b>\n",
    "\n",
    "<p><b>By comparing the two, the results are found to be identical.</p></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f2ec4",
   "metadata": {},
   "source": [
    "## 3. Compare with k-NN Euclidean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4dad17",
   "metadata": {},
   "source": [
    "### 3.1 k-NN Euclidean with different number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9e28a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors: 1\n",
      "Prediction results are:\n",
      " [1. 2. 3. 2. 3. 3. 2. 1. 2. 1. 3. 3. 2. 1. 2. 1. 1. 1. 3. 2. 2. 3. 2. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn kNN Classfier (Euclidean) is:\n",
      " 0.8611111111111112\n",
      "Confusion matrix of sklearn kNN Classifer (Euclidean) is:\n",
      " [[12  3  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2 11]]\n",
      "**********DIVIDER**********\n",
      "\n",
      "Number of neighbors: 3\n",
      "Prediction results are:\n",
      " [1. 2. 3. 2. 3. 2. 2. 1. 2. 1. 3. 3. 2. 1. 2. 1. 1. 1. 3. 2. 2. 3. 2. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn kNN Classfier (Euclidean) is:\n",
      " 0.8333333333333334\n",
      "Confusion matrix of sklearn kNN Classifer (Euclidean) is:\n",
      " [[12  3  0]\n",
      " [ 0  8  0]\n",
      " [ 0  3 10]]\n",
      "**********DIVIDER**********\n",
      "\n",
      "Number of neighbors: 5\n",
      "Prediction results are:\n",
      " [1. 2. 3. 2. 3. 2. 2. 1. 2. 1. 3. 2. 2. 2. 2. 1. 1. 1. 3. 2. 2. 3. 2. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn kNN Classfier (Euclidean) is:\n",
      " 0.7777777777777778\n",
      "Confusion matrix of sklearn kNN Classifer (Euclidean) is:\n",
      " [[11  4  0]\n",
      " [ 0  8  0]\n",
      " [ 0  4  9]]\n",
      "**********DIVIDER**********\n",
      "\n",
      "Number of neighbors: 7\n",
      "Prediction results are:\n",
      " [1. 2. 3. 2. 3. 2. 2. 1. 2. 1. 3. 2. 2. 1. 2. 1. 1. 1. 2. 2. 2. 3. 2. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn kNN Classfier (Euclidean) is:\n",
      " 0.7777777777777778\n",
      "Confusion matrix of sklearn kNN Classifer (Euclidean) is:\n",
      " [[12  3  0]\n",
      " [ 0  8  0]\n",
      " [ 0  5  8]]\n",
      "**********DIVIDER**********\n",
      "\n",
      "Time spend for sklearn kNN Classfier (Euclidean): 0:00:00.011079\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "#don't specify parameter 'metric', set 'p' = 2 instead to apply Euclidean distance, try different number of neighbors, see the difference among results\n",
    "for i in (1, 3, 5, 7):\n",
    "    print(\"Number of neighbors:\", i)\n",
    "    sklearn_classfier = KNeighborsClassifier(n_neighbors=i, p=2)\n",
    "\n",
    "    #fit the classfier from the train dataset\n",
    "    sklearn_classfier.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "    #predict test dataset\n",
    "    y_test_pred = sklearn_classfier.predict(X_test.to_numpy())\n",
    "    print(\"Prediction results are:\\n\", y_test_pred)\n",
    "    #accuracy score\n",
    "    print(\"Accuracy score for sklearn kNN Classfier (Euclidean) is:\\n\", accuracy_score(y_test, y_test_pred))\n",
    "    #confusion matrix\n",
    "    print(\"Confusion matrix of sklearn kNN Classifer (Euclidean) is:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "    #divider\n",
    "    print(\"**********DIVIDER**********\\n\")\n",
    "end = datetime.now()\n",
    "print(\"Time spend for sklearn kNN Classfier (Euclidean):\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a9e5f",
   "metadata": {},
   "source": [
    "### 3.2 k-NN DTW with different number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3b167d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbors: 1\n",
      "Prediction results are: [1. 2. 3. 1. 3. 3. 2. 1. 3. 1. 3. 3. 1. 1. 2. 1. 1. 1. 3. 2. 2. 3. 2. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn kNN Classfier (DTW) is:\n",
      " 0.9444444444444444\n",
      "Confusion matrix of sklearn kNN Classifer (DTW) is:\n",
      " [[14  1  0]\n",
      " [ 0  8  0]\n",
      " [ 0  1 12]]\n",
      "**********DIVIDER**********\n",
      "\n",
      "Number of neighbors: 3\n",
      "Prediction results are: [1. 2. 3. 1. 3. 2. 2. 1. 2. 1. 3. 3. 1. 1. 2. 1. 1. 1. 3. 2. 2. 3. 2. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn kNN Classfier (DTW) is:\n",
      " 0.8888888888888888\n",
      "Confusion matrix of sklearn kNN Classifer (DTW) is:\n",
      " [[14  1  0]\n",
      " [ 0  8  0]\n",
      " [ 0  3 10]]\n",
      "**********DIVIDER**********\n",
      "\n",
      "Number of neighbors: 5\n",
      "Prediction results are: [1. 2. 3. 1. 3. 2. 2. 1. 2. 1. 2. 2. 1. 1. 2. 1. 1. 1. 3. 2. 2. 3. 2. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn kNN Classfier (DTW) is:\n",
      " 0.8333333333333334\n",
      "Confusion matrix of sklearn kNN Classifer (DTW) is:\n",
      " [[14  1  0]\n",
      " [ 0  8  0]\n",
      " [ 0  5  8]]\n",
      "**********DIVIDER**********\n",
      "\n",
      "Number of neighbors: 7\n",
      "Prediction results are: [1. 2. 3. 1. 3. 2. 2. 1. 2. 1. 3. 2. 1. 2. 2. 1. 1. 1. 3. 2. 2. 3. 2. 3.\n",
      " 1. 3. 2. 2. 3. 1. 2. 1. 3. 1. 2. 1.]\n",
      "Accuracy score for sklearn kNN Classfier (DTW) is:\n",
      " 0.8333333333333334\n",
      "Confusion matrix of sklearn kNN Classifer (DTW) is:\n",
      " [[13  2  0]\n",
      " [ 0  8  0]\n",
      " [ 0  4  9]]\n",
      "**********DIVIDER**********\n",
      "\n",
      "Time spend for sklearn kNN Classfier (Euclidean): 0:01:56.420081\n"
     ]
    }
   ],
   "source": [
    "#try different number of neighbors, see the difference among results, use the best window size found from above task\n",
    "start = datetime.now()\n",
    "for i in (1,3,5,7):\n",
    "    print(\"Number of neighbors:\", i)\n",
    "    sklearn_classfier = KNeighborsClassifier(metric=calc_distance_dtw, n_neighbors=i, metric_params={'window': 5})\n",
    "    #fit the classfier with train set\n",
    "    sklearn_classfier.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "    #make predictions\n",
    "    y_test_pred = sklearn_classfier.predict(X_test.to_numpy())\n",
    "    print(\"Prediction results are:\", y_test_pred)\n",
    "    #check accuracy\n",
    "    print(\"Accuracy score for sklearn kNN Classfier (DTW) is:\\n\", accuracy_score(y_test, y_test_pred))\n",
    "    #check confusion metrics\n",
    "    print(\"Confusion matrix of sklearn kNN Classifer (DTW) is:\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "    #divider\n",
    "    print(\"**********DIVIDER**********\\n\")\n",
    "end = datetime.now()\n",
    "print(\"Time spend for sklearn kNN Classfier (Euclidean):\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7d0bd",
   "metadata": {},
   "source": [
    "<h5><b>Conclusion</b></h5>\n",
    "<p><b>Compare the results of Euclidean Classfier and DTW Classfier, we can draw conclusions in the following areas:</b></p>\n",
    "<p><b>\n",
    "&nbsp;&nbsp;- Accuracy: When we assign the best window size (which is 5 I found) to the DTW Classfier, the accuracy scores are always higher than those from the Euclidean Classfier when tesing under different numbers of neighbor. So, when we want to reach higher accuracy, DTW may be the choice.\n",
    "</b></p>\n",
    "<p><b>\n",
    "&nbsp;&nbsp;- Efficiency: However, when it comes to efficiency, the Euclidean Classfier consumes much less time than the DTW Classfier when the number of neighbor is relatively greater. So when there is not enough computational resource or efficiency is prefered, the Euclidean Classfier may be prefered.\n",
    "</b></p>\n",
    "<p><b>\n",
    "Besides, for this dataset, the greater the number of neighbor is, the lower accuracy score will be.\n",
    "</b></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('other')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa2f63693cbe8a677cb7b201038102bd07b8a84186c73f722b9b9f8abaa242bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
